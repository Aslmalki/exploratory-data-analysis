{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aslmalki/exploratory-data-analysis/blob/main/Data_Cleaning_Template_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Basic Steps as Data exploration.\n",
        "Where Data exploration refers to the initial step in data analysis in which data analysts use data visualization and statistical techniques to describe dataset characterizations, such as size, quantity, and accuracy, in order to better understand the nature of the data.*italicized text*"
      ],
      "metadata": {
        "id": "QAmciQC1vXU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuI6dWHAgs58"
      },
      "outputs": [],
      "source": [
        "# import the important lib\n",
        "import pandas as pd       #data processing\n",
        "import numpy as np        #linear algebra\n",
        "import datetime as dt\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#data visualisation\n",
        "import seaborn as sns\n",
        "import plotly\n",
        "\n",
        "# import your Dataset / put your dataset between the single paranthesis\n",
        "df = sns.load_dataset('Your Dataset');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "Fek_eCL1g3MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() #The head() method returns the first 5 rows of your dataset plus the coulomn names too"
      ],
      "metadata": {
        "id": "CnkYY2bvg4lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpvvj2Algs6B"
      },
      "outputs": [],
      "source": [
        "df.shape #the number of rows and columns of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # The info() method prints information about the DataFrame. The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values)."
      ],
      "metadata": {
        "id": "aHTO_2HYiHAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is so important to make sure the column data types is right, for example if the column was for price and the data type was intger , here you nedd to do one more step as data ccleaning whicch is change that column data types to be floating, etc."
      ],
      "metadata": {
        "id": "lfUdSxZskQkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1h8UQfIgs6E"
      },
      "outputs": [],
      "source": [
        "df.describe() #The describe() method returns statistical description of the data in the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the DataFrame contains numerical data, the description contains these information for each column:\n",
        "\n",
        "1. count - The number of not-empty values.\n",
        "2. mean - The average (mean) value.\n",
        "3. std - The standard deviation.\n",
        "4. min - the minimum value.\n",
        "5. 25% - The 25% percentile.\n",
        "6. 50% - The 50% percentile.\n",
        "7. 75% - The 75% percentile.\n",
        "8. max - the maximum value."
      ],
      "metadata": {
        "id": "Oy9JSCsZihEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the row/column if possible values are missing or null. {'any', 'all'}, default 'any'. choos from that what you need\n",
        "#'any':If any NA values are present, drop that row or column.\n",
        "#'all': If all values are NA, drop that row or column.\n",
        "\n",
        "df=df.dropna(how='all') # drop the row, if all the values are missing\n",
        "\n",
        "df=df.dropna(how='any') # drop the row, if any NA values are present\n",
        "\n",
        "df=df.drop_duplicates() # method helps in removing duplicates rows"
      ],
      "metadata": {
        "id": "d35XYrUOg0_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wG9Xt7cks-cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra steps you might need it with your dataset, depend on what are you looking for and what you need to do"
      ],
      "metadata": {
        "id": "_kPpDTTetBXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmWXZ_LHgs6C"
      },
      "outputs": [],
      "source": [
        "#specify the number of smallest values to be selected and the name of the column\n",
        "df.nsmallest(3, 'columnName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ROqDa0ngs6D"
      },
      "outputs": [],
      "source": [
        "#specify the number of largest values to be selected and the name of the column\n",
        "df.nlargest(5, 'columnName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgqX__YFgs6E"
      },
      "outputs": [],
      "source": [
        "# this is an example of some exploration steps, you can find certain values inside that column based on condition\n",
        "df1 = df.query('columnName >= 4') # you can do any other conditions filters\n",
        "print(df1.shape) # check the new total or raws and columns after this filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfunesOdgs6F"
      },
      "outputs": [],
      "source": [
        "# this is an example of some exploratory data analysis steps, The GROUPBY function allows you to group, aggregate, sort, and filter data based on the fields you specify.\n",
        "df2=df1.groupby(['1st columnName', '2nd columnName']).agg('sum')\n",
        "df2.head() #The head() method returns the first 5 rows of your dataset plus the coulomn names too\n",
        "print(df2.shape) # check the new total or raws and columns after this filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExCNu1aegs6G"
      },
      "outputs": [],
      "source": [
        "#This is useful when the index needs to be treated as a column,\n",
        "#or when the index is meaningless and needs to be reset to the default before another operation\n",
        "df2.reset_index()\n",
        "print(df2.shape) # check the new total or raws and columns\n",
        "df2.head() #The head() method returns the first 5 rows of your dataset plus the coulomn names too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsCnbcaigs6I"
      },
      "outputs": [],
      "source": [
        "#The axes_style() function for Seaborn library defines and returns a dictionary of the parameters related to the styling of the plots.\n",
        "sns.axes_style()\n",
        "plt.style.available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxdTwu8Qgs6M"
      },
      "outputs": [],
      "source": [
        "# Calculating mean and Stdev of certain column (numerical data)\n",
        "df_mean = np.mean(df[\"columnName\"])\n",
        "df_std = np.std(df[\"c\"])\n",
        "print(\"Mean of the columnName is % s \" %(np.mean(df[\"columnName\"])))\n",
        "print(\"Stdev of the columnName is % s \" %(np.std(df[\"columnName\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fszlV76Ggs6N"
      },
      "outputs": [],
      "source": [
        "#creat new column df['new_column_name']to filter perior column or any other reason\n",
        "# lambda to creat a function,like short one. axis=1 for rows level only ,axis=0 for columns level\n",
        "# here is an example from Taxi dataset, the new column will be the filter of the tip column where the tip is bigger than Zero\n",
        "df['giving_tip'] = df.apply (lambda row: row['tip'] > 0, axis=1) #the new column named Tip, you can change that to any name you want for your dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SEfaJwqgs6N"
      },
      "outputs": [],
      "source": [
        "# lambda to creat a function,like short one.\n",
        "#“axis 0” represents columns and “axis 1” represents rows.\n",
        "#creat new column that results from spearate an existing column\n",
        "# here is an example from Taxi dataset, the new column will be the filter of the pickup and dropoff column where the date is excluded and only the time kept\n",
        "df['pickup_time'] = df.apply (lambda row: row['pickup'].split(' ')[1], axis=1,)\n",
        "df['dropoff_time'] = df.apply (lambda row: row['dropoff'].split(' ')[1], axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6HFJd5mgs6P"
      },
      "outputs": [],
      "source": [
        "# convert a column to datetime format\n",
        "df['columnName']= pd.to_datetime(df['columnName'] )\n",
        "\n",
        "# Check the format of all the columns to make sure it was successful\n",
        "df.info()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}